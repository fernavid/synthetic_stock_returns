<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><title>Using Transformers to Generate Synthetic Stock Returns</title><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Courier New";font-style:normal}.c6{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c11{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c3{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c9{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c4{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c7{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c8{color:inherit;text-decoration:inherit}.c2{height:11pt}.c12{font-style:italic}.c10{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c7 doc-content"><p class="c11 title" id="h.gvy8d3f1jcdw"><span class="c9">Using transformers to simulate stock returns</span></p><p class="c0"><span>Fernando Vidal, Data Scientist at </span><span class="c4"><a class="c8" href="https://www.3fourteenresearch.com/">3Fourteen Research</a></span><span>&nbsp;Twitter: </span><span class="c4"><a class="c8" href="https://twitter.com/fernavid">@fernavid</a></span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span>We will use Andrej Karpathy&#39;s wonderfully easy to use </span><span class="c4"><a class="c8" href="https://github.com/karpathy/minGPT">minGPT</a></span><span class="c1">&nbsp;transformer library to see how well transformers do at generating realistic stock returns as measured by the S&amp;P 500. We will contrast the transformers results with the most basic model used to simulate stock returns: the gaussian distribution. The gaussian is definitely not perfect and much has been written as to why, but let&rsquo;s take a quick tour through 2 of the biggest problems with it that we will check if transformers solve for us.</span></p><h3 class="c3" id="h.6614v3487v68"><span class="c6">Fat Tails (Kurtosis)</span></h3><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 393.33px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 393.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">If we plot the daily returns of stocks since 1970 alongside a gaussian distribution fit with the mean and standard deviation of those same returns, we can see that we have a significant number of observations on each side well beyond what is predicted by the gaussian, ie. fat tails. So if we use a gaussian-based simulated stock series we will likely underestimate the chance for huge moves in a single day, something that could mess up our simulations and could cause us to drastically underestimate the true nature of equity risk.</span></p><p class="c0 c2"><span class="c1"></span></p><h3 class="c3" id="h.3ow6bl6lv2qo"><span class="c6">Volatility Clustering (Autoregressive Conditional Heteroskedasticity)</span></h3><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 346.67px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 346.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c1">Stock returns also have this very non-gaussian phenomenon of time-varying volatility where the level of volatility changes and persists at different levels for varying amounts of time. Gaussian noise of course is independently distributed and doesn&rsquo;t have this characteristic. </span></p><h3 class="c3" id="h.l9y7d6vhg633"><span class="c6">Transformers</span></h3><p class="c0"><span class="c1">Transformers are powerful neural networks that are able to model sequences of tokens to do things like predict the next token given a context of preceding tokens. This sounds right up our alley if we want to model stock data. For our purposes, I decided to use minGPT which provides very simple example code for building a Transformer model that takes an input text, trains a transformer, and then outputs new simulated text in the style of the original text. The example from the minGPT repository has the model try to learn to produce Shakespeare by inputting his complete works as the training data.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c1">Since stock returns are obviously not written in natural language, and I wanted to do a proof of concept quickly without hacking too deeply into the code to rework to accept time series data directly, I did something somewhat lazy but also I think kind of cool. I turn a series of daily returns like this:</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c5">array([ 0.00167095, -0.0032251 , &nbsp;0. &nbsp; &nbsp; &nbsp; &nbsp;, &nbsp;0.0049091 , -0.00310868,</span></p><p class="c0"><span class="c5">&nbsp; &nbsp; &nbsp; &nbsp;-0.00445486, -0.00704774, -0.00270398, -0.00033889, &nbsp;0.00045204])</span></p><p class="c0 c2"><span class="c5"></span></p><p class="c0"><span class="c1">Into this:</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c5">5347321344</span></p><p class="c0 c2"><span class="c5"></span></p><p class="c0"><span class="c1">Basically, the vocabulary of our model consists of just 10 characters, the numbers 0-9, each representing what decile of returns each day&rsquo;s return falls into. This means the model will be able to capture the general nature of returns without having to predict a precise number. The plan is to take the model&rsquo;s outputs and translate them back into actual simulated returns by sampling from the desired decile in the original dataset. So if the model predicts one day we will have a return of &ldquo;5&rdquo;, we will decode this by picking a random value from the original stock returns that is between the 50th and 60th percentile values. </span></p><h3 class="c3" id="h.v72ws8vfm15x"><span class="c6">Training our model</span></h3><p class="c0"><span>Loading up the </span><span class="c10">chargpt.py </span><span>script from the minGPT repo and replacing Shakespeare&rsquo;s complete writings text file with our coded stock returns was a simple enough matter. We choose a set of hyperparameters for our training process called &ldquo;</span><span class="c10">gpt-nano</span><span>&rdquo; which is basically consistent with a highly scaled down version of GPT2. We change the </span><span class="c10">block_size</span><span class="c1">&nbsp;variable to 128, which means that we can provide up to 128 trading days (roughly 6-months) worth of stock returns as a context to the model from which to make predictions. This means the model will predict based on at most 6-months worth prior values of stock returns. Just imagine the model is a technical analyst given a 6-month price chart and then asked to give a forecast.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span>After training for a couple hours on an M1 Macbook Air the training loss on the model starts at 2.3 which is precisely what to expect of an untrained network since our vocabulary size is 10 characters ln(10)=2.3. After training we get this down to 1.5, meaning the model is definitely learning </span><span class="c12">something </span><span class="c1">about the returns that helps it make forecasts that look more and more realistic.</span></p><h3 class="c3" id="h.73oram2l74re"><span class="c6">Using our model</span></h3><p class="c0"><span class="c1">Now the fun part. Let&rsquo;s generate some fake stock returns! To start, I will seed it with the most recent 6-months worth of stock returns as of January 26th, 2023. This means the model now knows what we know about how stocks have moved over the past 6 months. Now we ask the model to simulate for us the next 10 years of stock returns. Let&rsquo;s take a look at one path that the model hallucinated as a future for stocks. </span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 378.67px;"><img alt="" src="images/image6.png" style="width: 624.00px; height: 378.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Pretty realistic looking path for stocks. The stories write themselves! The strong post-COVID expansion of the early 2020s, Black Wednesday in December 2028 where we dropped 15% in a single day as the robot wars kicked off. But let&#39;s take a look and see if these returns actually preserved the stylized features of actual stock returns by revisiting our original charts.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 401.33px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 401.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">Nice, so we have fat tails just like actual stock returns do. But this is to be expected as when we decode, we are essentially pulling out real values from the stock return dataset. This is also what is behind the common synthetic data technique called bootstrapping, so our decoding method does the heavy lifting here. Let&rsquo;s move on to the more tricky problem of ensuring we have preserved volatility clustering.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 376.00px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 376.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c1">Good news here too! This looks really good, as we have periods of elevated volatility that persist for convincingly long periods of time just like real stock returns. </span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c1">So this is a pretty cool result, but what else did the model learn? What about the expected return of stocks over the long run? The training data had stocks go up ~7.5% per year on average. We just estimated a single path of 10 years into the future, but let&rsquo;s investigate how well the model thinks stocks will do on average over the long run by having it generate a large number of possible paths of stock returns over the next 10 years.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 388.00px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 388.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c1">So looking at the average path across all cases, we get an annualized expected return of about ~7.5%, which is very close to the actual average annualized return in the original data. Good sign!</span></p><p class="c0 c2"><span class="c1"></span></p><h3 class="c3" id="h.ldvwvfp135o2"><span class="c6">Final thoughts</span></h3><p class="c0"><span class="c1">These exercises offer some evidence that transformers can capture many of the stylized features of stock return distributions that the gaussian distribution fails to capture. There are many other features of stock returns we can investigate as a followup to this. For example, the S&amp;P 500 has a classic trading rule where you only invest when above the 200-day moving average which has historically improved risk adjusted returns. Do our simulated set of series preserve this feature in the majority of paths? If it doesn&rsquo;t, does that mean this trading rule is just a fluke of the particular path of data realized, or does it mean that our transformer model missed out on this feature of the data distribution? These are the questions that make synthetic data generation for something as complex as stocks a very tricky business. </span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c1">Another idea that comes to mind is that stocks don&rsquo;t trade in a vacuum, and the data distribution is certainly dependent on many other things like other asset classes, macroeconomic data, etc. Is there a way for us to create a token vocabulary that encodes more information about the rest of the financial markets, and generate synthetic data across a broad array of assets? Imagine we had a token that represented a day when stocks outperformed bonds while commodities underperformed both of them, and other tokens for every other combination of ways multiple assets can zig and zag. Then you could build a transformer that can generate forecasts that have the covariance structure of all assets built into its data generation process. This would come in very handy for building optimal portfolios for example. Lots of fun stuff to think about here.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0"><span class="c1">All the code is provided in the notebook file included in <a href="https://github.com/fernavid/synthetic_stock_returns">this</a> repository. And I hope you found this as much of a fun exercise as I did. Huge thanks to Andrej Karpathy, whose Youtube courses on transformers and language models I thoroughly enjoyed and who inspired me to play around and try to learn more about these new models.</span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0 c2"><span class="c1"></span></p><p class="c0 c2"><span class="c1"></span></p></body></html>
